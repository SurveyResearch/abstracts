\documentclass[11pt,twoside]{article}
\usepackage[toc,page,header]{appendix}
\usepackage{pdfpages}
\usepackage{csquotes}
\usepackage{changepage}
\usepackage{fontspec}
\defaultfontfeatures{Scale=MatchLowercase}
\setmainfont[Mapping=tex-text]{Times New Roman}
\setsansfont[Mapping=tex-text]{Arial}
\setmonofont{Courier}

\usepackage{float}
\usepackage{turnstile}
\usepackage{bussproofs}

\usepackage{geometry}
\geometry{letterpaper}

\newtheorem{theorem}{Theorem}
%\newtheorem{cor}{Corollary}
%\newtheorem{lem}{Lemma}
%\theoremstyle{remark}
\newtheorem{remark}{Remark}

\newtheorem{objection}{Objection}
\newenvironment*{response}[1][]{\noindent
\textbf{Response to Objection #1.}
\begin{adjustwidth}{1em}{1em}
}
{\end{adjustwidth}
\vspace{1ex}
}


%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent

\usepackage{graphicx}
\usepackage[leftcaption]{sidecap}
\sidecaptionvpos{figure}{c}

%\usepackage{amssymb}

\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\usepackage[
bibstyle=numeric,
citestyle=authortitle,
natbib=true,
hyperref,bibencoding=utf8,backref=true,backend=biber]{biblatex}

\usepackage{hyperref}
\hypersetup{
    bookmarks=true,         % show bookmarks bar?
    unicode=true,          % non-Latin characters in Acrobat’s bookmarks
    pdftoolbar=true,        % show Acrobat’s toolbar?
    pdfmenubar=true,        % show Acrobat’s menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={My title},    % title
    pdfauthor={Author},     % author
    pdfsubject={Subject},   % subject of the document
    pdfcreator={Creator},   % creator of the document
    pdfproducer={Producer}, % producer of the document
    pdfkeywords={keyword1} {key2} {key3}, % list of keywords
    pdfnewwindow=true,      % links in new window
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=blue,          % color of internal links
    citecolor=blue,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}
\usepackage{draftwatermark}


\usepackage{fancyhdr}
\setlength{\headheight}{15.2pt}
\pagestyle{fancy}

\lhead[IES Interim]{\thepage}
\chead[]{}
\rhead[\thepage]{IES Interim}

\title{Abstracts}
\author{G. A. Reynolds}
\date{\today}
\bibliography{%
../bib/abstracts.bib,%
../bib/causality.bib,%
../bib/em.bib,%
../bib/logic.bib,%
../bib/mind.bib,%
../bib/philosophy.bib,%
../bib/pragmatism.bib,%
../bib/psychomet.bib%
../bib/psychometrics.bib,%
../bib/misc.bib,%
../bib/measurement.bib,%
../bib/psychology.bib,%
../bib/variables.bib,%
../bib/val.bib,%
../bib/validity.bib,%
}

%% Macros

\newcommand{\SM}{Standard Model}
\newcommand{\XSM}{Extended Standard Model}

\newcommand{\SMeth}{Survey Methodology}

\newcommand{\SR}{Survey Research}
\newcommand{\sr}{survey research}
\newcommand{\SRIV}{Survey Interview}
\newcommand{\sriv}{survey interview}
\newcommand{\SIV}{Survey Interviewing}
\newcommand{\FI}{Field Interviewer}
\newcommand{\Iver}{Interviewer}
\newcommand{\R}{Respondent}
\newcommand{\LPR}{Legal Permanent Resident}
\newcommand{\ART}{Assimilated Response Technique}
\newcommand{\GAM}{Grouped Answer Method}
\newcommand{\IOM}{Instrument of Measurement}

\includeonly{%
%% pilots,cards
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\maketitle
\nocite{*}

\begin{abstract}
abstract
\end{abstract}

\tableofcontents
\listoffigures

\newpage
%%%%%%%%%%%%%%%%%%%%
\section{Pragmatism and \SR{}}

\begin{abstract}
\end{abstract}


%%%%%%%%%%%%%%%%%%%%
\section{A Critique of the Theory of Cognitive Interviewing}

\begin{abstract}
  
\end{abstract}

%%%%%%%%%%%%%%%%%%%%
\section{Mensuration without Representation}

\begin{abstract}
Measurement pragmatism.  No representation needed.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%
\section{Deflating Validity}

\begin{abstract}
Semantic and metaphysical deflationism works as well for validity as
it does for truth and reference.
\end{abstract}

\begin{remark}
  Deflationism seems to depend essentially on some form of
  expressivism.  Or maybe they amount to the same thing?
\end{remark}

\subsection{Validity, Reliability, Error}
\label{sub:Validity}

\begin{remark}
What is the point of worrying about validity?  Is it something in the
world that we are trying to discover?  Then we're trying to find ``the
right description of the world'' (Putnam).  Or is it a concept, so
that validity talk is about conceptual analysis and definition?

Or: we try to find the right description, and validity talk is part of
how we decide that we have found it.

\end{remark}

\begin{remark}
Why do psychometricians and the like worry so about validity?

Hypothesis: when they say ``validity'', what they're really interested
in is scientific legitimacy.  Effectively, to say that a test (etc.)
is valid is to say that it is in fact scientific.  Thats the practical
import of the concept of validity for them.

Unpack this.  Expose the assumptions and implications.
\end{remark}

\begin{remark}
  The problem with validity (quantifiability) is circularity.  If the
  task is to show that some property is quantitative, we have to do
  this without relying on quantitative vocabulary.  So for example, if
  we want to show that temperature is quantitative, we cannot use the
  concept of a unit of temperature to do so, because that presupposes
  just the outcome we are supposed to demonstrate.  This is similar to
  the problem we face in seeking to account for representational
  vocabulary in non-representational terms.

  quantifiability v. validity?  distinct problems, but the latter
  depends on the former?
\end{remark}

key concepts:

\begin{itemize}
\item validity treated as a special kind of property - of what?
\item constructs
\item (latent) variables
\item indicators
\end{itemize}

``validity'' as code for:

\begin{itemize}
\item legitimacy
\item vindication
\item credibility
\item proof (good premises + valid inference)
\end{itemize}

\begin{remark}
  On the idea that validity something (a property, etc.) that we look
  for in scientific theories in order to distinguish good ones from
  bad: see Putnam on fact/value distinction.  We use value judgments -
  simplicity, parsimony, etc. - in every aspect of science (thought),
  esp. in weeding out bad theories.  For there is no external or
  objective criterion of acceptability for theories to which we can
  appeal, nor is there any such citerion that does not involve value
  judgments.
\end{remark}

\begin{remark}
  So along with the fact/value distinction, and the analytic/synthetic
  distinction, the internal/external distinction also collapses?  Or
  do we just exclude the notion of external?  No; we need to retain
  the idea of an external world that is independent of us and to which
  some of our judgments are answerable.  We don't get to just make
  stuff up and call it true (correct) for at least some of our claims.
  There is no external absolute authority that can decide for us which
  theories are true, or rather which we should endorse, but that does
  not mean there is no external world that is authoritative for some
  of our sayings.  But isn't that trying to have it both ways?  How
  can our theories answer to the world if we cannot appeal to the
  world or some other external authority to sort them out?  See
  Brandom.

Related issue: what counts as evidence?  How do we decide?  What are
we doing when we decide that something counts as strong (weak)
evidence in support of a theory?  What are the criteria of adequacy
for an account of evidence?
\end{remark}

\subsection{RCT and Self-validation}

See Cartwright on RCT as self-validating.  This seems to mean that
RCTs are valid by construction.

This nicely parallels industrial QA notions of guaranteeing quality by
designing a production process that prevents defects.

What's the logic here?  Is self-validation really possible?  How can a
process validate itself - isn't the very idea inherently circular?  Or
rather, don't we land in a regress?  After all, if the idea is to
specify a process that yields validity, how do we know that that
process is itself valid?

\subsection{Deflation}

How can we get out of this mess?  One way is to deflate the notion of
validity, just deny that it is a substantive property.  When we claim
that a result is valid etc. what we are really saying is that we
endorse it, approve of it, etc.  It's an expressive device.  Compare
the semantic deflationist's idea that calling something true amounts
to endorsing or approving of it.

So if we discard the notion of validity (since it does no real work),
don't we find ourselves lacking something essential?  Well, we just
need a vocabulary that allows us to say explicitly the sorts of things
we find it useful to be able to express with respect to a study or qx
technique.  For example: credibility, utility, legitimacy,
vindication, justification, etc.

\begin{remark}
  The notion of validity seems to be connected to the problem of
  deciding which theories we should endorse.  What are the criteria of
  adequacy for any notion (or theory) of validity?  Or: what are the
  requirements that should be met by any purported explanation of
  validity?  Both particular cases and the general idea.  Tarski gives
  us something like this for logical validity; what about ``validity''
  as the term is used by psychometricians, test theorists, etc.?

Contrast: claims of validity for a case, v. explanation of what
validity is.


\end{remark}

The objection will no doubt be that we need some kind of standard,
which is just to say that we want to measure this something (validity,
credibility, whatever).  Implicit in all this is the notion that there
is some ``objective'' fact of the matter to which our
study/technique/etc. is ansswerable. A study is valid iff - what?  If
it meets some definite ``objective'' criteria.  Methodological
criteria, conditions of validity, etc.  In the psychometrics and
testing tradition this appeal to external authority is expressed as
something along the lines of ``measures what it purports to measure''.
Which is only meaningful insofar as a) there is actually something
there to measure, and b) it is in fact susceptibel to measurement.

And usually this is expressed in statistical terms.  But that dog
won't hunt either - you cannot get to validity via statistics.  All
you can do is measure central tendencies and variance - not enough to
establish validity, which is a substantive notion. (analysis
elsewhere).

To say that sth is valid is just to say that it is admirable
(Peirce?), or perhaps that it is virtuous, that it has the virtues we
prize.

%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Deontic Scorekeeping Model of Discursive Practice and \SR{}}

\begin{abstract}
Why the deontic scorekeeping model is preferable to others, esp. the
cognitive model.
\end{abstract}

\begin{remark}
  It's a model of discursive, that is rational, practice.  Contrast
  this with most models on offer which tend to focus on subpersonal
  processes; hence the prevalence of talk about ``the survey
  process'', the ``response process'', etc.
\end{remark}

%%%%%%%%%%%%%%%%%%%%%%%%
\section{A Quality Assurance Model for \SR{}}

\begin{abstract}
abstract
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%
\section{Causality and the Space of Reasons}

\begin{abstract}
abstract
\end{abstract}

\noindent
\cite{abell_narrative_2004} \\
\cite{crane_mental_1995} \\
\cite{gross_pragmatist_2009} \\
\cite{jackson_mental_1996} \\
\cite{lowe_causal_1993} \\
\cite{lowe_non-cartesian_2006} \\
\cite{macdonald_mental_1986} \\
\cite{menzies_causation_1993} \\
\cite{morris_causes_1986} \\
\cite{williamson_broadness_1998}

\section{Vocabularies}

Measurement as description.  Description v. evaluation.  Price on
naturalisms.  The bifurcation thesis.

\section{Conflation of Causal and Logical Relations}



\section{Fact-Value}

Messick, for one, conflates two kinds of fact/value distinction.  The
Kantian idea that we structure our own experience (etc.), Sellars'
Myth of the Given, and etc. - such stuff shows how there is no data
that is ``objective'' and given i.e. ``data is theory-laden''.

So facts involve what Putnam calls ``epistemic values''.

Messick confuses epistemic and ethical values.  He seems to think that
although we cannot arrive at value-free facts, this is because brute
facts are always packaged with ethical values.  The idea seems to be
that ethical values are something separate from facts but always
attached to them somehow.  Whereas the real problem is that there is
no genuine distinction between fact and (epistemic) value.  Facts
express (as it were) our epistemic values.

Messick's confusion is clear in his distinction between the scientific
and social ``roles'' of validity - as if the social (value-laden)
aspect of (Messickian) validity is something distinct from the
science.  ``[I]t is fundamental that score validation is an empirical
evaluation of the meaning and consequences of measurement.  As such,
validation combines scientific inquiry with rational argument to
justify (or nullify) score interpretation and use.'' (p. 742) But
``scientific inquiry'' and ``rational argument'' are not two distinct
things that can be combined.  They are the same thing, at least
conceptually.  If there is a difference here, it is sociological -
science as a way of conduction oneself, etc.

Messickian validity boils down to some notion of empirical support for
theoretical explanations.  For him ``evidential basis'' seems to
correspond to ``real'' science, and ``consequential basis'' to
``rational argument''.

``[B]oth meaning and values are integral to the concept of
validity...'' (p. 747).  The problem here is that the contrast with
value is fact, not meaning.

``Meaning'' is not something that can be empirically ``validated''.

\section{Word-World}

One problem with e.g. Messick is fuzziness about the relation of
language to world.  Ditto for any notion of ``measuring a concept''.

Re: validity: is it supposed to be a property of things in the world,
or just a concept?  Per Messick, validity is ``associated with'' score
interpretation and use.  This would seem to imply that it is a matter
of language (concepts).  But the language is just sloppy; ``score
interpretation'' might (should) refer to how we take a score to relate
to some fact in the world, in which case the question is just what is
validity-in-the-world.

In any case, Messick's whole discussion is muddled on this point; it
is rarely clear when he is talking about facts, concepts, or the
relation between the two.  Is a ``construct'' supposed to be something
in the world or a concept the describes some aspect of the world?

Construct v. ``indicators''.

Compare positivist notions of observational language v. theoretical
language.  So-called indicators are (I understand) supposed to be
empirical observables.  Their relation to the construct is (must be) a
matter of theory; but then is that theoretical (conceptual) structure
to be taken as a mirror of reality, such that the construct is a real
(albeit ``hidden'') bit of the world and its relations to the
indicators are real relations in the world?

\section{Hypothetical Entities}

Putnam, Brandom, etc. - if the existence of (some) hypotheticals makes
no difference in the way things are then we can just discard them.  As
Putnam puts it, ``Would mathematics \it{work} one bit less well if
these funny objects \it{stopped} existing?  Those who posit ``abstract
entities''  to account for the success of mathematics do not claim that we (or any other things in the empirical world) \it{interact} with the abstract entities.  But if any entities do not interact with us or with the empirical world \it{at all}, then doesn't it follow that \it{everything wouuld be the same if they didn't exist}?'' (Collapse, p. 33)

This points out another problem with e.g. latent variables, namely
that they are supposed to have causal powers, but, insofar as they are
abstract at least, they have no connection to the empirical world and
so cannot cause anything.  The counterargument would presumably be
that hidden does not necessarily mean abstract.  But in that case they
must have a location in space-time, even if we don't know what it is.
But this just leads to more problems: where are hidden psychological
processes supposed to occur?  It can't be the brain, since they are
(by stipulation) psychological, not neurological.

So it seems we have no choice but to treat postulation of hidden stuff
as a matter of Brandomian methodological pragmatism: useful, but
without ontological consequences.  ``Constructs'' may be useful for
explaining observable indicators, but they don't really exist in any
meaningful sense.  But the usual story goes the other way around:
indicators are useful because they are how we get constructs.

\section{Personal v. Subpersonal}

Reasons v. causes

\section{Spaces}

\subsection{Natural space of causes}

\subsection{Discursive space of reasons}

\section{Notes}

\subsection{Evolution}

Instead of "the QA process", the proper object of investigation is the
local evolution of discourse.

EM studies local produced order.  It may come up with a structural
description.  But locally produced order is the outcome of an
essentially evolutionary process - the mutual adaptation of the
participants to each other and the context.  Also, any such model may
not (probably will not) generalize.  But what does generalize is the
evolutionary mechanism itself, just like in biology.

Rational selection as the mechanism of the evolution of discursive
performances.  What accounts for the deontic attitudes we adopt
regarding performances?  Brandom's account describes the architecture
of such posturings and the significances the institute.  But it does
not really address the logic of discourse as an evolutionary process.

The idea is that Brandom provides an account of discourse qua rational
action.  Different attitudes are endorsed or undertaken for reasons -
that is the source or ground of the intelligibility of discursive
practice.  So if we view the unfolding of discourse as being governed
by the logic of evolution, we can treat Brandom's sort of rational
pragmatism as the selection mechanism that accounts for why some
attitudes (meanings) survive (are endorsed) and others do not.
Meanings that survive must fit into the space of reasons - they must
be assertable and justifiable, even if the participants are unable to
explicitly articulate this.  This makes the evolution of discourse
intelligible as a rational process, rather than a natural process.
Responses to questions are not explicable as effects caused by "true
values" or the like; this would make them fundamentally non-rational.
Or to borrow a bon mot from Garfinkel, this would make respondents
"rational dopes".

Similar language: "negotiation", e.g. "...I suggest that the content
of talk indicates that imposed hierarchies are continually
re-negotiated..."  Negotiation as rational evolution?

The "true score" and other orthodox models account for sentience, not
sapience.

\subsection{Verum Factum}

Cartesianism (spectator, etc.) inspection, discovery, certainty,
foundationism (external foundation grounding knowledge) v.

Verum Factum, geneological/historical, following growth/development,
not certainty but ???; no foundationism, no priviledged vocab, no
external source of authority

Critical notions: authority.  For evidence etc. key idea is authority - the only
kind of authority is the kind we assent to.  So the question is what
do we treat as authoritative and why, rather than how can we discover
the One True external foundational source of authority and learn to
speak its language

Critical notions: vocabulary.  Regardless of what there is, we can
only talk about it by using vocabs.

Relevance to SR: we make our truths, by engaging in dialog with
respondents in order to teach/train them to understand what we want.
In other words we work to make our scorecards converge.  We can never
be sure that researchers and respondents understand each other, have
the same interpretations of qx text, etc.  But we can do what nature
does in evolution and learning: institute a cyclic process of
experiment, feedback, and correction.  This is operational even at the
most simple and basic level of communication.  So we can use this fact
to our advantage.

Communication interactions as not essentially different from processes
of evolution and learning.  Evolutionary process tend to coordinate
organism and environment; learning processes adapt the learner to the
task environment, etc.  Any discursive exchange - even simple
greetings, etc. - does the same sort of thing: coordinate and mutually
adjust the parties to the exchange.

\subsection{Rational Evidence}

Evidence-Based Rational SR

RCT: isolate the causal factor that links Treatment to Outcome

THe mistake make by orthodox SR (shown by its vocab of measurement,
error, etc.) is that it confuses the space of causes and the space of
reasons.

In RCT, we observe a stimulus followed by a response (T followed by O)
and postulate a causal relation.  In SR, we observe a Q performance
followed by a R performance.  In fact this is an idealization since Q
and R cannot be isolated - they are both joint performances.  Ignore
that for now; the point is that what makes them intelligible as
performances is the space of reasons, not causes.  That is, as
discursive episodes they are essentially rational in a way the T-O
trials are not.  By definition, "rational" means involving concepts.
Stimulus-response does not involve concepts and so is not rational in
this favored sense.  The natural world may be lawful, but it is not
rational.

So SR should abandon the orthodox vocab of measurment, etc. in favor
of one involving rationality.  What would "evidence-based" mean, then?
Not the kind of evidence involve in natural science, since such
evidence does not involve concepts and thus meaning.  Instead evidence
inescapably involves meaning and understanding.  What counts as
evidence is what we count as a rational explanation or story.  And
this necessarily involves the perspective of the participants - it is
their rationality, their giving and asking for reasons, that provides
the observational basis of evidence.

 One consequence: Qx does not involve measurement.  SR can use stats
 to statistically measure the collected data, but that is quite
 separate from whether the data measure anything.  So you can say that
 x\% of resondents pick option X, but that does not mean that you have
 measured the distribution of "true values" of some latent variable.
 What you have measure is a distribution of deontic scores, or
 discursive postures.  There is no warrant for claiming that each
 member of the x\% means the same thing by picking X.

\subsection{Misc}

1.  What is a question?  Better: what counts as a question, what is it to ask a question?

2.  Ditto for answer.

Q and A as parts of a whole (holistic view)

Q token v. Q performance, etc.

\subsection{Erotetic Discursive Practice}


EDP as production of data rather than discovery of truth

\subsection{Replication}

Goal is replication.  Compare: blood work, e.g. measuring
cholesteral.  The measuring apparatus reacts to the sample, not the
other way around.  For EDP, respondent reacts to the question, so the
question is analogous to the blood sample.  The response is a kind of
measurement of the question, not the other way around.

Replicability means same setup, same experimental conditions; in EDP
this means replication of conceptual structure, which is accomplished
by the dialog preceding the question.  Traditionally, "ask the same
question"; in practice this is impossible, since what counts is not
the question text but respondent's grasp of the sense.  So the
"experimental setup" should be viewed as the work of teaching the
respondent what the sense of the question is.  Survey interviewing is
essentially interventionist, but this is not necessarily a bad thing,
since lab experiments are too - they "intervene" to set up
experimental "initial conditions".  The difference is that setting up
initial conditions ("same meaning") in question asking means tutoring
the respondent.

\subsection{Myths and Mythologies}

\begin{itemize}
\item The Myth of Question Independence says that the meaning of a
    question is independent of context.  But the meaning of a question
    is always dependent on what came before it.
\item Myth of Autonomy. Interviewer and Respondent.
\item Myth of Error
\end{itemize}

\subsection{Dopes}

Garfinkel's dopes - cultural, judgmental, psychological

Dehumanization.  Orthodox Survey Research (OSR) dehumanizes
participants.  The R is a sampling unit.  The mythology of OSR
measurement treats the human R as a natural object to be measured
rather than a person.


\clearpage
\appendix
\begin{appendices}
\section{Bibliography}
%% \addcontentsline{toc}{chapter}{Bibliography}
%% \bibliographystyle{plainnat}
\printbibliography[heading=none]
\end{appendices}

\end{document}
